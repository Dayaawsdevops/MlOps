# ─────────────────────────────────────────────────────────────────
# GitHub Actions — Image Classification MLOps Pipeline
#
# FIXES APPLIED:
#   1. EC2 repo path changed from ~/image-mlops → ~/MlOps
#   2. EC2 auto-start before training
#   3. EC2 auto-stop after training (if: always)
#   4. DVC uses snap installation (/snap/bin/dvc)
#   5. venv path corrected
#   6. S3_BUCKET secret added to all steps that need it
#
# REQUIRED GITHUB SECRETS:
#   AWS_ACCESS_KEY_ID       — github-actions-mlops access key
#   AWS_SECRET_ACCESS_KEY   — github-actions-mlops secret key
#   AWS_REGION              — us-east-1
#   AWS_ACCOUNT_ID          — 150245645484
#   EC2_HOST                — Public IP of your EC2 instance
#   EC2_SSH_KEY             — Full contents of mlops-key.pem
#   ECR_REPOSITORY          — image-classifier
#   ECS_CLUSTER             — mlops-cluster
#   ECS_SERVICE             — image-classifier-svc
#   ECS_TASK_DEFINITION     — image-classifier-td
#   S3_BUCKET               — mlops-medical-images-daya
# ─────────────────────────────────────────────────────────────────

name: Image Classification MLOps Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      epochs:
        description: 'Number of training epochs'
        required: false
        default: '10'

env:
  AWS_REGION:      ${{ secrets.AWS_REGION }}
  ECR_REGISTRY:    ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com
  ECR_REPOSITORY:  ${{ secrets.ECR_REPOSITORY }}
  IMAGE_TAG:       ${{ github.sha }}

jobs:

  # ══════════════════════════════════════════════════════════════
  # JOB 1 — Unit Tests (free — runs on GitHub servers)
  # ══════════════════════════════════════════════════════════════
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install CPU-only dependencies
        run: |
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
          pip install fastapi uvicorn[standard] Pillow python-multipart boto3 pytest httpx mlflow

      - name: Run tests
        run: |
          # PYTHONPATH tells pytest where to find the src module
          export PYTHONPATH=$PYTHONPATH:$(pwd)
          # Skip tests that need a trained model (metadata.json doesn't exist yet)
          pytest tests/ -v --tb=short \
            -k "not val_accuracy and not metadata"

  # ══════════════════════════════════════════════════════════════
  # JOB 2 — Start EC2 Instance
  # ══════════════════════════════════════════════════════════════
  start-ec2:
    name: Start EC2 Instance
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main'
    outputs:
      instance_id: ${{ steps.get-id.outputs.instance_id }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Get EC2 instance ID
        id: get-id
        run: |
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=mlops-trainer" \
                      "Name=instance-state-name,Values=stopped,running" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text)
          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
          echo "Instance ID: $INSTANCE_ID"

      - name: Start EC2 instance
        run: |
          aws ec2 start-instances \
            --instance-ids ${{ steps.get-id.outputs.instance_id }}
          echo "Waiting for instance to be running..."
          aws ec2 wait instance-running \
            --instance-ids ${{ steps.get-id.outputs.instance_id }}
          echo "Instance is running!"

      - name: Wait for SSH to be ready
        run: |
          echo "Waiting 30 seconds for SSH to be ready..."
          sleep 30

  # ══════════════════════════════════════════════════════════════
  # JOB 3 — Train on EC2
  # EC2 is ALWAYS stopped after this job — even if training fails
  # ══════════════════════════════════════════════════════════════
  train:
    name: Train on EC2
    runs-on: ubuntu-latest
    needs: start-ec2
    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_KEY }}" > ~/.ssh/ec2_key.pem
          chmod 600 ~/.ssh/ec2_key.pem
          ssh-keyscan -H ${{ secrets.EC2_HOST }} >> ~/.ssh/known_hosts

      - name: Get latest EC2 IP
        run: |
          PUBLIC_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=mlops-trainer" \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text)
          echo "EC2_IP=$PUBLIC_IP" >> $GITHUB_ENV
          echo "EC2 IP: $PUBLIC_IP"

      - name: Sync code to EC2
        run: |
          rsync -avz \
            --exclude='.git' \
            --exclude='__pycache__' \
            --exclude='data/' \
            --exclude='models/' \
            -e "ssh -i ~/.ssh/ec2_key.pem -o StrictHostKeyChecking=no" \
            ./ ubuntu@${{ secrets.EC2_HOST }}:~/MlOps/

      - name: Train model on EC2
        id: training
        run: |
          ssh -i ~/.ssh/ec2_key.pem \
            -o StrictHostKeyChecking=no \
            ubuntu@${{ secrets.EC2_HOST }} << 'ENDSSH'
            set -e
            cd ~/MlOps

            # Activate virtual environment
            source ~/venv/bin/activate

            # Pull latest data from S3 using snap dvc
            echo "Pulling data from S3..."
            /snap/bin/dvc pull

            # Run training
            echo "Starting training..."
            python src/train.py \
              --epochs ${{ github.event.inputs.epochs || '10' }} \
              --batch-size 16 \
              --lr 0.001 \
              --img-size 224

            # Push trained model back to S3
            echo "Pushing model to S3..."
            /snap/bin/dvc push

            echo "Training complete!"
          ENDSSH

      # ── CRITICAL: ALWAYS STOP EC2 ─────────────────────────────
      # Runs even if training fails — prevents surprise charges
      - name: Stop EC2 instance (always runs)
        if: always()
        run: |
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=mlops-trainer" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text)
          echo "Stopping EC2 instance $INSTANCE_ID..."
          aws ec2 stop-instances --instance-ids $INSTANCE_ID
          echo "EC2 stopped — billing stopped!"

      - name: Download model from S3
        if: steps.training.outcome == 'success'
        run: |
          mkdir -p models
          aws s3 cp s3://${{ secrets.S3_BUCKET }}/models/metadata.json models/metadata.json
          aws s3 cp s3://${{ secrets.S3_BUCKET }}/models/best_model.pth  models/best_model.pth

      - name: Upload model as artifact
        if: steps.training.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: models/
          retention-days: 7

  # ══════════════════════════════════════════════════════════════
  # JOB 4 — Quality Gate
  # ══════════════════════════════════════════════════════════════
  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: train

    steps:
      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: models/

      - name: Check accuracy threshold
        run: |
          python3 - << 'EOF'
          import json, sys
          with open("models/metadata.json") as f:
              meta = json.load(f)
          val_acc   = meta["val_acc"]
          threshold = 0.75
          print(f"Validation Accuracy : {val_acc:.4f} ({val_acc*100:.1f}%)")
          print(f"Required Threshold  : {threshold:.4f} ({threshold*100:.1f}%)")
          if val_acc < threshold:
              print("FAILED — model blocked from deployment.")
              sys.exit(1)
          print("PASSED — proceeding to deploy.")
          EOF

  # ══════════════════════════════════════════════════════════════
  # JOB 5 — Build Docker Image & Push to ECR
  # ══════════════════════════════════════════════════════════════
  build-and-push:
    name: Build & Push to ECR
    runs-on: ubuntu-latest
    needs: quality-gate

    steps:
      - uses: actions/checkout@v4

      - name: Download trained model
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: models/

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Log in to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push image to ECR
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag  $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
                      $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
          echo "Image pushed: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"

      - name: Delete ECR images older than 30 days
        run: |
          aws ecr describe-images \
            --repository-name $ECR_REPOSITORY \
            --query "imageDetails[?imagePushedAt<\`$(date -d '30 days ago' -u +%Y-%m-%dT%H:%M:%SZ)\`].imageDigest" \
            --output text | tr '\t' '\n' | while read digest; do
              [ -n "$digest" ] && aws ecr batch-delete-image \
                --repository-name $ECR_REPOSITORY \
                --image-ids imageDigest=$digest \
                && echo "Deleted old image: $digest"
            done

  # ══════════════════════════════════════════════════════════════
  # JOB 6 — Deploy to ECS Fargate
  # ══════════════════════════════════════════════════════════════
  deploy:
    name: Deploy to ECS Fargate
    runs-on: ubuntu-latest
    needs: build-and-push

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Download task definition
        run: |
          aws ecs describe-task-definition \
            --task-definition ${{ secrets.ECS_TASK_DEFINITION }} \
            --query taskDefinition > task-def.json

      - name: Update ECS task definition with new image
        id: task-def
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: task-def.json
          container-name:  image-classifier
          image:           ${{ env.ECR_REGISTRY }}/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}

      - name: Deploy to ECS service
        uses: aws-actions/amazon-ecs-deploy-task-definition@v1
        with:
          task-definition: ${{ steps.task-def.outputs.task-definition }}
          service:         ${{ secrets.ECS_SERVICE }}
          cluster:         ${{ secrets.ECS_CLUSTER }}
          wait-for-service-stability: true

      - name: Smoke test deployment
        run: |
          sleep 30
          LB_DNS=$(aws ecs describe-services \
            --cluster ${{ secrets.ECS_CLUSTER }} \
            --services ${{ secrets.ECS_SERVICE }} \
            --query 'services[0].loadBalancers[0].dnsName' \
            --output text)
          echo "Testing http://$LB_DNS/health ..."
          curl -f "http://$LB_DNS/health" && echo "Deployment healthy!"
